{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b0ac5b7-a55b-4cc1-8c13-4bf92804ed37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as fcn\n",
    "import pandas\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql.window import Window\n",
    "import os\n",
    "from marel.services import ServiceProvider\n",
    "from marel.databricks import DatabricksProvider\n",
    "provider = DatabricksProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2aff5c05-e8de-4ef9-b4fd-4c0a352562fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Months = 9\n",
    "df_sx_telemetry = spark.table('marel_digital_machines.sensorx.marel_sensorx_telemetry')\n",
    "df_sx_telemetry = df_sx_telemetry.filter(fcn.col('timeStamp') > fcn.add_months(fcn.current_date(),-Months)).select(\n",
    "    \"timeStamp\",\n",
    "    \"properties_deviceId\",\n",
    "    \"payload_xrayController_filamentCurrent\",\n",
    "    \"payload_xrayController_temperature\",\n",
    "    \"payload_xrayController_tubeCurrent\",\n",
    "    \"payload_xrayController_tubeVoltage\",\n",
    "    \"payload_xrayController_onTime\"\n",
    ")\n",
    "\n",
    "df_sx_telemetry.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48f3c612-125a-4af5-8bc1-2236ad249d55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Months = 9\n",
    "df_sx_serialnumber = (\n",
    "    spark.table(\"marel_digital_machines.sensorx.marel_sensorx_xraycontroller_property_serialnumber\")\n",
    "    .filter(fcn.col(\"timeStamp\") > fcn.add_months(fcn.current_date(), -Months))\n",
    "    .groupBy(\"properties_deviceId\", \"payload_serialNumber\")\n",
    "    .agg(\n",
    "        fcn.min(\"timeStamp\").alias(\"FirstTimestamp\"),\n",
    "        fcn.max(\"timeStamp\").alias(\"NewestTimestamp\")\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c202f818-ebfc-452c-9eeb-7bd111d648c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as fcn, Window\n",
    "\n",
    "BIN_SIZE_SECONDS = 86400\n",
    "\n",
    "T = df_sx_telemetry.alias(\"T\")\n",
    "S = df_sx_serialnumber.alias(\"S\")\n",
    "\n",
    "df_sx_telemetry_serialnumber = (\n",
    "    T.hint(\"range_join\", BIN_SIZE_SECONDS)\n",
    "     .join(\n",
    "        S,\n",
    "        (fcn.col(\"T.properties_deviceId\") == fcn.col(\"S.properties_deviceId\")) &\n",
    "        (fcn.col(\"T.timeStamp\") >= fcn.col(\"S.FirstTimestamp\")) &\n",
    "        (fcn.col(\"T.timeStamp\") <= fcn.col(\"S.NewestTimestamp\")),\n",
    "        how=\"left\"\n",
    "     )\n",
    "     .select(\"T.*\", fcn.col(\"S.payload_serialNumber\").alias(\"serialNumber\"))\n",
    ")\n",
    "\n",
    "df_sx_telemetry_serialnumber.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fd48c45-f930-40d2-8a35-547a69db07d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Testa seinna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67ff999d-3d91-42b0-92b9-5c5adecebfb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Backward fill serialNumber for nulls, partitioned by device and ordered by time descending\n",
    "window_spec = Window.partitionBy(\"properties_deviceId\").orderBy(fcn.col(\"timeStamp\").desc())\n",
    "df_sx_telemetry_serialnumber_filled = df_sx_telemetry_serialnumber.withColumn(\n",
    "    \"serialNumber\",\n",
    "    fcn.last(\"serialNumber\", ignorenulls=True).over(window_spec)\n",
    ")\n",
    "\n",
    "display(df_sx_telemetry_serialnumber_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8ddae9b-9f4f-42a8-b358-722bf75184b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, Window\n",
    "\n",
    "Months = 9\n",
    "df_sx_xraycontroller_fault = spark.table('marel_digital_machines.sensorx.marel_sensorx_xraycontroller_property_fault').filter(\n",
    "    (fcn.col('timeStamp') > fcn.add_months(fcn.current_date(),-Months)) &\n",
    "    (fcn.col('payload_fault_faultName') == \"faultRegulation\")\n",
    ").select(\"timeStamp\",\"properties_deviceId\",\"payload_fault_faultName\",\"payload_fault_state\")\n",
    "\n",
    "df_sx_xraycontroller_fault.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "237211f9-c21f-4e69-a488-f0993af07136",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F, Window\n",
    "\n",
    "# Telemetry (no casting needed)\n",
    "telemetry = df_sx_telemetry_serialnumber.alias(\"t\")\n",
    "\n",
    "# Window per device ordered by timestamp\n",
    "w = Window.partitionBy(\"properties_deviceId\").orderBy(\"timeStamp\")\n",
    "\n",
    "# Build fault intervals\n",
    "fault_int = (\n",
    "    df_sx_xraycontroller_fault\n",
    "    .withColumn(\"LastTimeStamp\", F.lead(\"timeStamp\").over(w))\n",
    "    .alias(\"f\")\n",
    ")\n",
    "\n",
    "# Range join using timestamps directly\n",
    "df_sx_joined_regu_fault = telemetry.join(\n",
    "    fault_int,\n",
    "    (F.col(\"t.properties_deviceId\") == F.col(\"f.properties_deviceId\")) &\n",
    "    (F.col(\"t.timeStamp\") >= F.col(\"f.timeStamp\")) &\n",
    "    (F.col(\"f.LastTimeStamp\").isNull() | (F.col(\"t.timeStamp\") < F.col(\"f.LastTimeStamp\"))),\n",
    "    \"inner\"\n",
    ").select(\n",
    "    [F.col(f\"t.{c}\") for c in telemetry.columns] +\n",
    "    [F.col(f\"f.{c}\") for c in fault_int.columns if c not in [\"properties_deviceId\", \"timeStamp\", \"LastTimeStamp\"]]\n",
    ")\n",
    "\n",
    "df_sx_joined_regu_fault.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68b24c70-f60f-4522-9c4c-59e7319fe6cc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Untitled"
    }
   },
   "outputs": [],
   "source": [
    "df_csv = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .option(\"inferSchema\", True) \\\n",
    "    .option(\"multiLine\", True) \\\n",
    "    .option(\"escape\", \"\\\"\") \\\n",
    "    .option(\"quote\", \"\\\"\") \\\n",
    "    .option(\"delimiter\", \";\") \\\n",
    "    .load(\"/Volumes/teams/sensorx/data-dump/RegulationFault.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da005f82-33d7-4087-ba4b-2d3bfe2060bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "# create separate tables for 500W and 800W\n",
    "\n",
    "df_csv_500 = df_csv.filter(fcn.col(\"GeneratorType\") == \"500W\")\n",
    "df_csv_800 = df_csv.filter(fcn.col(\"GeneratorType\") == \"800W\")\n",
    "\n",
    "csv_500 = df_csv_500.alias(\"csv_500\")\n",
    "sx  = df_sx_joined_regu_fault.alias(\"sx\")\n",
    "\n",
    "df_sx_joined_regu_fault_500 = (\n",
    "    csv_500.join(\n",
    "        sx,\n",
    "        F.col(\"csv_500.ProductID\") == F.col(\"sx.serialNumber\"),\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .select(\n",
    "        *([F.col(f\"sx.{c}\") for c in df_sx_joined_regu_fault.columns] +\n",
    "          [F.col(\"csv_500.GeneratorType\")])\n",
    "    )\n",
    ")\n",
    "\n",
    "csv_800 = df_csv_800.alias(\"csv_800\")\n",
    "df_sx_joined_regu_fault_800 = (\n",
    "    csv_800.join(\n",
    "        sx,\n",
    "        F.col(\"csv_800.ProductID\") == F.col(\"sx.serialNumber\"),\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    .select(\n",
    "        *([F.col(f\"sx.{c}\") for c in df_sx_joined_regu_fault.columns] +\n",
    "          [F.col(\"csv_800.GeneratorType\")])\n",
    "    )\n",
    ")\n",
    "df_sx_joined_regu_fault_500.cache()\n",
    "df_sx_joined_regu_fault_800.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e73c03c-b3b6-477b-bb1b-c15af9da098d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c635210d-1094-4aa9-b02b-9df66fdc56e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Plotting up known cases of earlier failiures from February and March 2025 and pairing with failiure message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c0bdf1d-1344-474b-af13-45f61a421917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_sx_telemetry_earlier = (\n",
    "    spark.table(\"marel_digital_machines.sensorx.marel_sensorx_telemetry\")\n",
    "    .filter(\n",
    "        (F.col(\"timeStamp\") >= F.to_timestamp(F.lit(\"2025-02-01 00:00:00\"))) &\n",
    "        (F.col(\"timeStamp\") <  F.to_timestamp(F.lit(\"2025-04-01 00:00:00\")))\n",
    "    )\n",
    "    .select(\n",
    "        \"timeStamp\",\n",
    "        \"properties_deviceId\",\n",
    "        \"payload_xrayController_filamentCurrent\",\n",
    "        \"payload_xrayController_temperature\",\n",
    "        \"payload_xrayController_tubeCurrent\",\n",
    "        \"payload_xrayController_tubeVoltage\",\n",
    "        \"payload_xrayController_onTime\"\n",
    "    )\n",
    ")\n",
    "\n",
    "Months = 3\n",
    "df_sx_xraycontroller_fault_earlier = spark.table('marel_digital_machines.sensorx.marel_sensorx_xraycontroller_property_fault').filter(\n",
    "        (F.col(\"timeStamp\") >= F.to_timestamp(F.lit(\"2025-02-01 00:00:00\"))) &\n",
    "        (F.col(\"timeStamp\") <  F.to_timestamp(F.lit(\"2025-04-01 00:00:00\")))\n",
    "    ).select(\"timeStamp\",\"properties_deviceId\",\"payload_fault_faultName\",\"payload_fault_state\")\n",
    "\n",
    "feb_faulty_machine = df_sx_telemetry_earlier.filter(F.col(\"properties_deviceId\") == \"08947f89-b3c1-4b1e-ed33-08d9f153eeaf\")\n",
    "feb_faulty_machine_fault = df_sx_xraycontroller_fault_earlier.filter(F.col(\"properties_deviceId\") == \"08947f89-b3c1-4b1e-ed33-08d9f153eeaf\")\n",
    "display(feb_faulty_machine_fault)\n",
    "\n",
    "march_faulty_machine = df_sx_telemetry_earlier.filter(F.col(\"properties_deviceId\") == \"0b479140-8371-4c78-b490-6fd37df535bc\")\n",
    "march_faulty_machine_fault = df_sx_xraycontroller_fault_earlier.filter(F.col(\"properties_deviceId\") == \"0b479140-8371-4c78-b490-6fd37df535bc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63cf185d-755f-4df5-8f48-f1d41d04575f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Teikna upp:\n",
    "\n",
    "ffm = feb_faulty_machine.toPandas()\n",
    "ffmf = feb_faulty_machine_fault.toPandas()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ffm[\"timeStamp\"], ffm[\"payload_xrayController_tubeCurrent\"])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "cleaning_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
